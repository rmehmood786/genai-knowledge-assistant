# ðŸ§  GenAI Knowledge Assistant

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)
![Streamlit](https://img.shields.io/badge/Built%20with-Streamlit-red?logo=streamlit)
![LangChain](https://img.shields.io/badge/Powered%20by-LangChain-forestgreen)
![Status](https://img.shields.io/badge/Mode-Offline%20%26%20Free-success)

![App Demo](demo.PNG)

A lightweight **retrieval-augmented generation (RAG)** app built with **LangChain**, **FAISS**, and **HuggingFace** (can be used fully **offline and free** for experimental tasks if don't want to use paid openAI credits).  
This project demonstrates how to build a retrieval-based knowledge assistant using your own documents without relying on paid APIs.

---

## ðŸš€ Features
- âœ… **Offline / Free** â€“ Uses `sentence-transformers` and `flan-t5-small` locally (no OpenAI key needed)
- ðŸ” **Document Search** â€“ Indexes and retrieves contextually relevant information using FAISS
- ðŸ’¬ **Conversational Interface** â€“ Ask natural language questions about your files
- ðŸ§© **Modular Architecture** â€“ Swap in OpenAI or HuggingFace models easily
- ðŸŒ **Streamlit UI** â€“ Simple, interactive web interface

---

## ðŸ“¦ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/rmehmood786/genai-knowledge-assistant.git
cd genai-knowledge-assistant

python -m venv .venv
.venv\Scripts\Activate.ps1  # (on Windows PowerShell)

pip install -r requirements.txt
```

---

## ðŸ§± Project Structure
```
genai-knowledge-assistant/
â”‚
â”œâ”€â”€ app.py                # Streamlit interface (main app)
â”œâ”€â”€ ingest.py             # Indexes local documents into FAISS
â”œâ”€â”€ config.py             # Configuration (API key, paths)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ docs/             # Place your .txt/.md/.pdf documents here
â”‚   â””â”€â”€ vectorstore/      # FAISS index will be stored here
â”œâ”€â”€ .env.example          # Example environment file
â””â”€â”€ README.md
```

---

## âš™ï¸ Usage

### 1. Add Your Documents
Put any `.txt`, `.md`, or `.pdf` files in `data/docs/`.

### 2. Create the FAISS Vector Store
```bash
python ingest.py
```
Youâ€™ll see a message like:
```
Saved FAISS index to data/vectorstore with 4 chunks.
```

### 3. Run the Streamlit App
```bash
streamlit run app.py
```

Then open your browser at:  
ðŸ”— `http://localhost:8501`

### 4. Ask Questions
Example prompts:
- â€œWhat does SmartCo Consulting do?â€
- â€œWhich technologies are mentioned in my documents?â€
- â€œSummarise the document about AI ethics.â€

---

## ðŸ§  Models Used
- **Embeddings:** `sentence-transformers/all-MiniLM-L6-v2`
- **LLM (offline):** `google/flan-t5-small`
- *(Optional)* You can still switch to OpenAI models by unchecking â€œUse free local LLMâ€ in the sidebar.

---

## ðŸ’¡ Future Enhancements
- Add document upload support directly in the UI
- Include context preview under each answer
- Support PDF â†’ text conversion
- Deploy via Streamlit Cloud or HuggingFace Spaces

---

## ðŸ‘¤ Author
**Rashid Mehmood**  
ðŸ“§ [rashidmehmood5914@gmail.com](mailto:rashidmehmood5914@gmail.com)  
ðŸ”— [LinkedIn](https://www.linkedin.com/in/rashid-mehmood-aimachinelearningengineer/) | [GitHub](https://github.com/rmehmood786)

---

## ðŸ§© Git Commands to Push Updates

From inside your project folder:

```powershell
cd "C:\Users\Rashid Mehmood\Downloads\genai-knowledge-assistant\genai-knowledge-assistant"
.venv\Scripts\Activate.ps1

git add .
git commit -m "update: fully offline version using HuggingFace + Flan-T5 with badges"
git branch -M main
git remote set-url origin https://github.com/rmehmood786/genai-knowledge-assistant.git
git push -u origin main
```

> âœ… **Note:** Ensure `.env` is in your `.gitignore` so your local API keys remain private.
